{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 2 - Question 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Stats 507, Fall 2021*\n",
    "\n",
    "Han Qiu  \n",
    "September 30, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "import math\n",
    "import scipy.stats as st\n",
    "from scipy.stats import sem\n",
    "from scipy.stats import norm\n",
    "from statistics import mean\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.a\n",
    "\n",
    "url1 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/DEMO_G.XPT'\n",
    "url2 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/DEMO_H.XPT'\n",
    "url3 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.XPT'\n",
    "url4 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_J.XPT'\n",
    "\n",
    "cols = ['SEQN', 'RIDAGEYR', 'RIDRETH3','DMDEDUC2','DMDMARTL',\n",
    "        'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR','RIAGENDR']\n",
    "\n",
    "df1 = pd.read_sas(url1)\n",
    "new_df1 = df1[cols].copy()\n",
    "new_df1['cohort']='1'\n",
    "final_df1 = new_df1.set_axis(['id', 'age', 'race/ethnicity', 'education', \n",
    "                            'marital status', 'exam_status', \n",
    "                            'masked variance pseudo-psu', \n",
    "                            'masked variance pseudo-stratum', \n",
    "                            '2 year mec exam weight', \n",
    "                            '2 year interview weight',\n",
    "                            'gender',\n",
    "                            'cohort'], axis=1, inplace=False)\n",
    "\n",
    "df2 = pd.read_sas(url2)\n",
    "new_df2 = df2[cols].copy()\n",
    "new_df2['cohort']='2'\n",
    "final_df2 = new_df2.set_axis(['id', 'age', 'race/ethnicity', 'education', \n",
    "                            'marital status', 'exam_status', \n",
    "                            'masked variance pseudo-psu', \n",
    "                            'masked variance pseudo-stratum', \n",
    "                            '2 year mec exam weight', \n",
    "                            '2 year interview weight',\n",
    "                            'gender',\n",
    "                            'cohort'], axis=1, inplace=False)\n",
    "\n",
    "df3 = pd.read_sas(url3)\n",
    "new_df3 = df3[cols].copy()\n",
    "new_df3['cohort']='3'\n",
    "final_df3 = new_df3.set_axis(['id', 'age', 'race/ethnicity', 'education', \n",
    "                            'marital status', 'exam_status', \n",
    "                            'masked variance pseudo-psu', \n",
    "                            'masked variance pseudo-stratum', \n",
    "                            '2 year mec exam weight', \n",
    "                            '2 year interview weight',\n",
    "                            'gender',\n",
    "                            'cohort'], axis=1, inplace=False)\n",
    "\n",
    "df4 = pd.read_sas(url4)\n",
    "new_df4 = df4[cols].copy()\n",
    "new_df4['cohort']='4'\n",
    "final_df4 = new_df4.set_axis(['id', 'age', 'race/ethnicity', 'education', \n",
    "                            'marital status', 'exam_status', \n",
    "                            'masked variance pseudo-psu', \n",
    "                            'masked variance pseudo-stratum', \n",
    "                            '2 year mec exam weight', \n",
    "                            '2 year interview weight',\n",
    "                            'gender',\n",
    "                            'cohort'], axis=1, inplace=False)\n",
    "\n",
    "\n",
    "convert_dict = {'id': int,\n",
    "                'age': int,\n",
    "                'race/ethnicity': 'category',\n",
    "                'education': 'category',\n",
    "                'marital status': 'category',\n",
    "                'exam_status': 'category',\n",
    "                'masked variance pseudo-psu': int,\n",
    "                'masked variance pseudo-stratum': int,\n",
    "                '2 year mec exam weight': float,\n",
    "                '2 year interview weight':float,\n",
    "                'gender': 'category',\n",
    "                'cohort': int\n",
    "               }\n",
    "\n",
    "all_df = [final_df1, final_df2, final_df3, final_df4]\n",
    "demo_df = pd.concat(all_df,axis=0)\n",
    "demo_df = demo_df.astype(convert_dict)\n",
    "\n",
    "# check column types\n",
    "print(demo_df.dtypes)\n",
    "\n",
    "# save to pickle format\n",
    "demo_df.to_pickle(\"./df.pkl\")\n",
    "\n",
    "# read pickle format file \n",
    "pkl_demo = pd.read_pickle(\"./df.pkl\")\n",
    "pkl_demo\n",
    "\n",
    "1.b\n",
    "\n",
    "url_d1 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/OHXDEN_G.XPT'\n",
    "url_d2 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/OHXDEN_H.XPT'\n",
    "url_d3 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/OHXDEN_I.XPT'\n",
    "url_d4 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/OHXDEN_J.XPT'\n",
    "\n",
    "# cohort 1\n",
    "\n",
    "dd1 = pd.read_sas(url_d1)\n",
    "dental_col1 = ['SEQN', 'OHDDESTS']\n",
    "dental_df1 = dd1[dental_col1].copy()\n",
    "\n",
    "dental_col1[0] = 'id'\n",
    "dental_col1[1] = 'ohx_status'\n",
    "den1 = dental_df1.set_axis(dental_col1, axis=1, inplace=False)\n",
    "\n",
    "# cohort 2\n",
    "dd2 = pd.read_sas(url_d2)\n",
    "dental_col2 = ['SEQN', 'OHDDESTS']\n",
    "dental_df2 = dd2[dental_col2].copy()\n",
    "\n",
    "dental_col2[0] = 'id'\n",
    "dental_col2[1] = 'ohx_status'\n",
    "den2 = dental_df2.set_axis(dental_col2, axis=1, inplace=False)\n",
    "\n",
    "# cohort 3\n",
    "\n",
    "dd3 = pd.read_sas(url_d3)\n",
    "dental_col3 = ['SEQN', 'OHDDESTS']\n",
    "dental_df3 = dd3[dental_col3].copy()\n",
    "\n",
    "dental_col3[0] = 'id'\n",
    "dental_col3[1] = 'ohx_status'\n",
    "den3 = dental_df3.set_axis(dental_col3, axis=1, inplace=False)\n",
    "\n",
    "# cohort 4\n",
    "\n",
    "dd4 = pd.read_sas(url_d4)\n",
    "dental_col4 = ['SEQN', 'OHDDESTS']\n",
    "dental_df4 = dd4[dental_col4].copy()\n",
    "\n",
    "dental_col4[0] = 'id'\n",
    "dental_col4[1] = 'ohx_status'\n",
    "den4 = dental_df4.set_axis(dental_col4, axis=1, inplace=False)\n",
    "\n",
    "# combine\n",
    "dental_df = [den1, den2, den3, den4]\n",
    "final_dental = pd.concat(dental_df,axis=0)\n",
    "final_dental['ohx_status'] = final_dental['ohx_status'] .astype('category')\n",
    "final_dental['id'] = final_dental['id'].astype(int)\n",
    "\n",
    "# check column types\n",
    "print(final_dental.dtypes)\n",
    "\n",
    "merged_df = pd.merge(demo_df,final_dental,how='left', left_on='id',right_on='id')\n",
    "\n",
    "merged_df.head(3)\n",
    "\n",
    "merged_df['under_20'] = [True if x < 20 else False for x in merged_df['age']]\n",
    "\n",
    "condition = [(merged_df['education'] == 4) | (merged_df['education'] == 5), \n",
    "             (merged_df['under_20'] == True)|\n",
    "             ((merged_df['education'] != 4)|(merged_df['education'] != 5))]\n",
    "answer = ['some college/college graduate', 'No college/<20']\n",
    "merged_df['college'] = np.select(condition, answer)\n",
    "\n",
    "condition2 = [(merged_df['exam_status'] == 2) & (merged_df['ohx_status'] == 1), \n",
    "              (merged_df['ohx_status'] != 1)]\n",
    "answer2 = ['complete', 'missing']\n",
    "merged_df['ohx'] = np.select(condition2, answer2)\n",
    "\n",
    "cols = ['id', 'gender', 'age', 'under_20', 'college', 'exam_status','ohx_status','ohx']\n",
    "new_df = merged_df[cols]\n",
    "new_df.head(5)\n",
    "\n",
    "1.c\n",
    "\n",
    "c_df = new_df.drop(new_df[new_df.exam_status != 2].index)\n",
    "c_df.head()\n",
    "\n",
    "num = len(new_df[new_df.exam_status != 2])\n",
    "print('The number of subjects removed : ' + str(num))\n",
    "print('The number of subjects remaining : ' + str(c_df.shape[0]))\n",
    "\n",
    "1.d\n",
    "\n",
    "under_tb = pd.crosstab(c_df['under_20'],c_df['ohx'])\n",
    "under_tb.index = ['20 or older','under 20']\n",
    "\n",
    "gender_tb = pd.crosstab(c_df['gender'],c_df['ohx'])\n",
    "gender_tb.index = ['male', 'female']\n",
    "\n",
    "col_tb = pd.crosstab(c_df['college'],c_df['ohx'])\n",
    "\n",
    "tb = pd.concat([under_tb, gender_tb, col_tb], axis=0)\n",
    "tb2 = tb.apply(lambda r: r/r.sum(), axis=1)\n",
    "\n",
    "tuples = [('age (mean/se)',''),\n",
    "         ('age < 20','20 or older'),\n",
    "         ('age < 20', 'under 20'),\n",
    "         ('gender', 'male'),\n",
    "         ('gender','female'),\n",
    "         ('college','no college/<20'),\n",
    "         ('college', 'some college/college graduate')]\n",
    "\n",
    "age_c = c_df[c_df.ohx == 'complete'].age.mean()\n",
    "age_m = c_df[c_df.ohx == 'missing'].age.mean()\n",
    "age_cd = stats.tstd(c_df[c_df.ohx == 'complete'].age)\n",
    "age_md = stats.tstd(c_df[c_df.ohx == 'missing'].age)\n",
    "\n",
    "\n",
    "f_format = \"{0:.0f}({1:.4}%)\"\n",
    "f_format2 = \"{0:.3f}({1:.4})\"        \n",
    "\n",
    "age0 = f_format2.format(age_c,age_cd)\n",
    "age1 = f_format2.format(age_m,age_md)\n",
    "          \n",
    "x0 = f_format.format(tb.iloc[0, 0],tb2.iloc[0, 0]*100)\n",
    "x1 = f_format.format(tb.iloc[1, 0],tb2.iloc[1, 0]*100)\n",
    "x2 = f_format.format(tb.iloc[2, 0],tb2.iloc[2, 0]*100)\n",
    "x3 = f_format.format(tb.iloc[3, 0],tb2.iloc[3, 0]*100)\n",
    "x4 = f_format.format(tb.iloc[4, 0],tb2.iloc[4, 0]*100)\n",
    "x5 = f_format.format(tb.iloc[5, 0],tb2.iloc[5, 0]*100)\n",
    "\n",
    "y0 = f_format.format(tb.iloc[0, 1],tb2.iloc[0, 1]*100)\n",
    "y1 = f_format.format(tb.iloc[1, 1],tb2.iloc[1, 1]*100)\n",
    "y2 = f_format.format(tb.iloc[2, 1],tb2.iloc[2, 1]*100)\n",
    "y3 = f_format.format(tb.iloc[3, 1],tb2.iloc[3, 1]*100)\n",
    "y4 = f_format.format(tb.iloc[4, 1],tb2.iloc[4, 1]*100)\n",
    "y5 = f_format.format(tb.iloc[5, 1],tb2.iloc[5, 1]*100)\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(tuples, names = ['variable name', 'level'])\n",
    "tb3 = pd.DataFrame({'complete':[age0,x0, x1, x2, x3, x4, x5],\n",
    "                  'missing': [age1,y0, y1, y2, y3, y4, y5]},\n",
    "                  index=index)\n",
    "\n",
    "# t-test\n",
    "age_p = stats.ttest_ind(c_df[c_df.ohx == 'complete'].age,c_df[c_df.ohx == 'missing'].age)[1]\n",
    "# Chi-square test of independence. \n",
    "p1= chi2_contingency(under_tb)[1]\n",
    "p2 = chi2_contingency(gender_tb)[1]\n",
    "p3 = chi2_contingency(col_tb)[1]\n",
    "\n",
    "tb3['p-value'] = [age_p,p1,'-',p2,'-',p3,'-']\n",
    "\n",
    "tb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                   int32\n",
      "age                                  int32\n",
      "race/ethnicity                    category\n",
      "education                         category\n",
      "marital status                    category\n",
      "interview/examination status      category\n",
      "masked variance pseudo-psu           int32\n",
      "masked variance pseudo-stratum       int32\n",
      "2 year mec exam weight             float64\n",
      "2 year interview weight            float64\n",
      "cohort                               int32\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>education</th>\n",
       "      <th>marital status</th>\n",
       "      <th>interview/examination status</th>\n",
       "      <th>masked variance pseudo-psu</th>\n",
       "      <th>masked variance pseudo-stratum</th>\n",
       "      <th>2 year mec exam weight</th>\n",
       "      <th>2 year interview weight</th>\n",
       "      <th>cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62161</td>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>104236.582554</td>\n",
       "      <td>102641.406474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62162</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>16116.354010</td>\n",
       "      <td>15457.736897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62163</td>\n",
       "      <td>14</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>7869.485117</td>\n",
       "      <td>7397.684828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62164</td>\n",
       "      <td>44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>127965.226204</td>\n",
       "      <td>127351.373299</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62165</td>\n",
       "      <td>14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>13384.042162</td>\n",
       "      <td>12209.744980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  age race/ethnicity education marital status  \\\n",
       "0  62161   22            3.0       3.0            5.0   \n",
       "1  62162    3            1.0       NaN            NaN   \n",
       "2  62163   14            6.0       NaN            NaN   \n",
       "3  62164   44            3.0       4.0            1.0   \n",
       "4  62165   14            4.0       NaN            NaN   \n",
       "\n",
       "  interview/examination status  masked variance pseudo-psu  \\\n",
       "0                          2.0                           1   \n",
       "1                          2.0                           3   \n",
       "2                          2.0                           3   \n",
       "3                          2.0                           1   \n",
       "4                          2.0                           2   \n",
       "\n",
       "   masked variance pseudo-stratum  2 year mec exam weight  \\\n",
       "0                              91           104236.582554   \n",
       "1                              92            16116.354010   \n",
       "2                              90             7869.485117   \n",
       "3                              94           127965.226204   \n",
       "4                              90            13384.042162   \n",
       "\n",
       "   2 year interview weight  cohort  \n",
       "0            102641.406474       1  \n",
       "1             15457.736897       1  \n",
       "2              7397.684828       1  \n",
       "3            127351.373299       1  \n",
       "4             12209.744980       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url1 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/DEMO_G.XPT'\n",
    "url2 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/DEMO_H.XPT'\n",
    "url3 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.XPT'\n",
    "url4 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_J.XPT'\n",
    "\n",
    "cols = ['SEQN', 'RIDAGEYR', 'RIDRETH3','DMDEDUC2','DMDMARTL',\n",
    "        'RIDSTATR', 'SDMVPSU', 'SDMVSTRA', 'WTMEC2YR', 'WTINT2YR']\n",
    "\n",
    "df1 = pd.read_sas(url1)\n",
    "new_df1 = df1[cols].copy()\n",
    "new_df1['cohort']='1'\n",
    "final_df1 = new_df1.set_axis(['id', 'age', 'race/ethnicity', 'education', \n",
    "                            'marital status', 'interview/examination status', \n",
    "                            'masked variance pseudo-psu', \n",
    "                            'masked variance pseudo-stratum', \n",
    "                            '2 year mec exam weight', \n",
    "                            '2 year interview weight', \n",
    "                            'cohort'], axis=1, inplace=False)\n",
    "\n",
    "df2 = pd.read_sas(url2)\n",
    "new_df2 = df2[cols].copy()\n",
    "new_df2['cohort']='2'\n",
    "final_df2 = new_df2.set_axis(['id', 'age', 'race/ethnicity', 'education', \n",
    "                            'marital status', 'interview/examination status', \n",
    "                            'masked variance pseudo-psu', \n",
    "                            'masked variance pseudo-stratum', \n",
    "                            '2 year mec exam weight', \n",
    "                            '2 year interview weight', \n",
    "                            'cohort'], axis=1, inplace=False)\n",
    "\n",
    "df3 = pd.read_sas(url3)\n",
    "new_df3 = df3[cols].copy()\n",
    "new_df3['cohort']='3'\n",
    "final_df3 = new_df3.set_axis(['id', 'age', 'race/ethnicity', 'education', \n",
    "                            'marital status', 'interview/examination status', \n",
    "                            'masked variance pseudo-psu', \n",
    "                            'masked variance pseudo-stratum', \n",
    "                            '2 year mec exam weight', \n",
    "                            '2 year interview weight', \n",
    "                            'cohort'], axis=1, inplace=False)\n",
    "\n",
    "df4 = pd.read_sas(url4)\n",
    "new_df4 = df4[cols].copy()\n",
    "new_df4['cohort']='4'\n",
    "final_df4 = new_df4.set_axis(['id', 'age', 'race/ethnicity', 'education', \n",
    "                            'marital status', 'interview/examination status', \n",
    "                            'masked variance pseudo-psu', \n",
    "                            'masked variance pseudo-stratum', \n",
    "                            '2 year mec exam weight', \n",
    "                            '2 year interview weight', \n",
    "                            'cohort'], axis=1, inplace=False)\n",
    "\n",
    "\n",
    "convert_dict = {'id': int,\n",
    "                'age': int,\n",
    "                'race/ethnicity': 'category',\n",
    "                'education': 'category',\n",
    "                'marital status': 'category',\n",
    "                'interview/examination status': 'category',\n",
    "                'masked variance pseudo-psu': int,\n",
    "                'masked variance pseudo-stratum': int,\n",
    "                '2 year mec exam weight': float,\n",
    "                '2 year interview weight':float,\n",
    "                'cohort': int\n",
    "               }\n",
    "\n",
    "demo_df = [final_df1, final_df2, final_df3, final_df4]\n",
    "final_demo_df = pd.concat(demo_df,axis=0)\n",
    "final_demo_df = final_demo_df.astype(convert_dict)\n",
    "\n",
    "# save to pickle format\n",
    "final_demo_df.to_pickle(\"./demo.pkl\")\n",
    "#df = pd.read_pickle(\"./demo.pkl\")\n",
    "\n",
    "# check column types\n",
    "print(final_demo_df.dtypes)\n",
    "\n",
    "final_demo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                           int32\n",
      "dentition status code     category\n",
      "tooth count 01            category\n",
      "tooth count 02            category\n",
      "tooth count 03            category\n",
      "                            ...   \n",
      "coronal tooth count 28    category\n",
      "coronal tooth count 29    category\n",
      "coronal tooth count 30    category\n",
      "coronal tooth count 31    category\n",
      "cohort                       int32\n",
      "Length: 63, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dentition status code</th>\n",
       "      <th>tooth count 01</th>\n",
       "      <th>tooth count 02</th>\n",
       "      <th>tooth count 03</th>\n",
       "      <th>tooth count 04</th>\n",
       "      <th>tooth count 05</th>\n",
       "      <th>tooth count 06</th>\n",
       "      <th>tooth count 07</th>\n",
       "      <th>tooth count 08</th>\n",
       "      <th>...</th>\n",
       "      <th>coronal tooth count 23</th>\n",
       "      <th>coronal tooth count 24</th>\n",
       "      <th>coronal tooth count 25</th>\n",
       "      <th>coronal tooth count 26</th>\n",
       "      <th>coronal tooth count 27</th>\n",
       "      <th>coronal tooth count 28</th>\n",
       "      <th>coronal tooth count 29</th>\n",
       "      <th>coronal tooth count 30</th>\n",
       "      <th>coronal tooth count 31</th>\n",
       "      <th>cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62162</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'D'</td>\n",
       "      <td>b'U'</td>\n",
       "      <td>b'U'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'Y'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>b'Z'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>b'S'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id dentition status code tooth count 01 tooth count 02 tooth count 03  \\\n",
       "0  62161                   1.0            4.0            2.0            2.0   \n",
       "1  62162                   1.0            4.0            4.0            4.0   \n",
       "2  62163                   1.0            4.0            2.0            2.0   \n",
       "3  62164                   1.0            4.0            2.0            2.0   \n",
       "4  62165                   1.0            4.0            2.0            2.0   \n",
       "\n",
       "  tooth count 04 tooth count 05 tooth count 06 tooth count 07 tooth count 08  \\\n",
       "0            2.0            2.0            2.0            2.0            2.0   \n",
       "1            1.0            1.0            1.0            1.0            1.0   \n",
       "2            2.0            2.0            2.0            2.0            2.0   \n",
       "3            2.0            2.0            2.0            2.0            2.0   \n",
       "4            2.0            2.0            2.0            2.0            2.0   \n",
       "\n",
       "   ... coronal tooth count 23 coronal tooth count 24 coronal tooth count 25  \\\n",
       "0  ...                   b'S'                   b'S'                   b'S'   \n",
       "1  ...                   b'D'                   b'D'                   b'D'   \n",
       "2  ...                   b'S'                   b'S'                   b'S'   \n",
       "3  ...                   b'S'                   b'S'                   b'S'   \n",
       "4  ...                   b'S'                   b'S'                   b'S'   \n",
       "\n",
       "  coronal tooth count 26 coronal tooth count 27 coronal tooth count 28  \\\n",
       "0                   b'S'                   b'S'                   b'S'   \n",
       "1                   b'D'                   b'D'                   b'D'   \n",
       "2                   b'S'                   b'S'                   b'S'   \n",
       "3                   b'S'                   b'S'                   b'S'   \n",
       "4                   b'S'                   b'S'                   b'S'   \n",
       "\n",
       "  coronal tooth count 29 coronal tooth count 30 coronal tooth count 31 cohort  \n",
       "0                   b'S'                   b'Z'                   b'S'      1  \n",
       "1                   b'D'                   b'U'                   b'U'      1  \n",
       "2                   b'S'                   b'Y'                   b'S'      1  \n",
       "3                   b'S'                   b'Z'                   b'Z'      1  \n",
       "4                   b'S'                   b'S'                   b'S'      1  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_d1 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2011-2012/OHXDEN_G.XPT'\n",
    "url_d2 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2013-2014/OHXDEN_H.XPT'\n",
    "url_d3 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/OHXDEN_I.XPT'\n",
    "url_d4 = 'https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/OHXDEN_J.XPT'\n",
    "\n",
    "# cohort 1\n",
    "\n",
    "dd1 = pd.read_sas(url_d1)\n",
    "dental_col1 = ['SEQN', 'OHDDESTS']\n",
    "\n",
    "for col in dd1.columns:\n",
    "    if re.match(r'OHX\\d+\\dTC',col) or re.match(r'OHX\\d+\\d+CTC',col):\n",
    "        dental_col1.append(col)\n",
    "\n",
    "dental_df1 = dd1[dental_col1].copy()\n",
    "dental_df1['cohort']='1'\n",
    "\n",
    "\n",
    "dental_col1[0] = 'id'\n",
    "dental_col1[1] = 'dentition status code'\n",
    "for i in range(len(dental_col1)):\n",
    "    if re.match('^OHX.*CTC$',dental_col1[i]):\n",
    "        dental_col1[i] = 'coronal tooth count '+ dental_col1[i][3:5]\n",
    "    elif re.match('^OHX.*TC$',dental_col1[i]):\n",
    "        dental_col1[i] = 'tooth count '+ dental_col1[i][3:5]\n",
    "            \n",
    "dental_col1.append('cohort')\n",
    "den1 = dental_df1.set_axis(dental_col1, axis=1, inplace=False)\n",
    "\n",
    "# cohort 2\n",
    "\n",
    "dd2 = pd.read_sas(url_d2)\n",
    "dental_col2 = ['SEQN', 'OHDDESTS']\n",
    "\n",
    "for col in dd2.columns:\n",
    "    if re.match(r'OHX\\d+\\dTC',col) or re.match(r'OHX\\d+\\d+CTC',col):\n",
    "        dental_col2.append(col)\n",
    "\n",
    "dental_df2 = dd2[dental_col2].copy()\n",
    "dental_df2['cohort']='2'\n",
    "\n",
    "dental_col2[0] = 'id'\n",
    "dental_col2[1] = 'dentition status code'\n",
    "for i in range(len(dental_col2)):\n",
    "    if re.match('^OHX.*CTC$',dental_col2[i]):\n",
    "        dental_col2[i] = 'coronal tooth count '+ dental_col2[i][3:5]\n",
    "    elif re.match('^OHX.*TC$',dental_col2[i]):\n",
    "        dental_col2[i] = 'tooth count '+ dental_col2[i][3:5]\n",
    "            \n",
    "dental_col2.append('cohort')\n",
    "den2 = dental_df2.set_axis(dental_col2, axis=1, inplace=False)\n",
    "\n",
    "# cohort 3\n",
    "\n",
    "dd3 = pd.read_sas(url_d3)\n",
    "dental_col3 = ['SEQN', 'OHDDESTS']\n",
    "\n",
    "for col in dd3.columns:\n",
    "    if re.match(r'OHX\\d+\\dTC',col) or re.match(r'OHX\\d+\\d+CTC',col):\n",
    "        dental_col3.append(col)\n",
    "\n",
    "dental_df3 = dd3[dental_col3].copy()\n",
    "dental_df3['cohort']='3'\n",
    "\n",
    "dental_col3[0] = 'id'\n",
    "dental_col3[1] = 'dentition status code'\n",
    "for i in range(len(dental_col3)):\n",
    "    if re.match('^OHX.*CTC$',dental_col3[i]):\n",
    "        dental_col3[i] = 'coronal tooth count '+ dental_col3[i][3:5]\n",
    "    elif re.match('^OHX.*TC$',dental_col3[i]):\n",
    "        dental_col3[i] = 'tooth count '+ dental_col3[i][3:5]\n",
    "            \n",
    "dental_col3.append('cohort')\n",
    "den3 = dental_df3.set_axis(dental_col3, axis=1, inplace=False)\n",
    "\n",
    "# cohort 4\n",
    "\n",
    "dd4 = pd.read_sas(url_d4)\n",
    "dental_col4 = ['SEQN', 'OHDDESTS']\n",
    "\n",
    "for col in dd4.columns:\n",
    "    if re.match(r'OHX\\d+\\dTC',col) or re.match(r'OHX\\d+\\d+CTC',col):\n",
    "        dental_col4.append(col)\n",
    "\n",
    "dental_df4 = dd4[dental_col4].copy()\n",
    "dental_df4['cohort']='4'\n",
    "\n",
    "dental_col4[0] = 'id'\n",
    "dental_col4[1] = 'dentition status code'\n",
    "for i in range(len(dental_col4)):\n",
    "    if re.match('^OHX.*CTC$',dental_col4[i]):\n",
    "        dental_col4[i] = 'coronal tooth count '+ dental_col4[i][3:5]\n",
    "    elif re.match('^OHX.*TC$',dental_col4[i]):\n",
    "        dental_col4[i] = 'tooth count '+ dental_col4[i][3:5]\n",
    "            \n",
    "dental_col4.append('cohort')\n",
    "den4 = dental_df4.set_axis(dental_col4, axis=1, inplace=False)\n",
    "\n",
    "# combine\n",
    "dental_df = [den1, den2, den3, den4]\n",
    "final_dental = pd.concat(dental_df,axis=0)\n",
    "final_dental[dental_col1] = final_dental[dental_col1].astype('category')\n",
    "final_dental[['id','cohort']] = final_dental[['id','cohort']].astype(int)\n",
    "\n",
    "# check column types\n",
    "print(final_dental.dtypes)\n",
    "\n",
    "# save to pickle format\n",
    "final_dental.to_pickle(\"./dental.pkl\")\n",
    "#df = pd.read_pickle(\"./dental.pkl\")\n",
    "\n",
    "final_dental.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of cases in demographic datasets is 39156\n",
      "The number of cases in dental datasets is 35909\n"
     ]
    }
   ],
   "source": [
    "print( 'The number of cases in demographic datasets is ' + str(final_demo_df.shape[0]))\n",
    "print( 'The number of cases in dental datasets is ' + str(final_dental.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
